# ğŸ”§ TorchServe API Wrapper with Auto-Benchmarking

A secure and production-ready Python package to serve PyTorch models using TorchServe, with built-in API wrapper, performance benchmarking tools, and example notebooks.

---

## ğŸš€ Features

- ğŸ” **Secure REST API** with token-based authentication
- ğŸ§  **Model Deployment** using [TorchServe](https://pytorch.org/serve/)
- âš™ï¸ **Auto-Benchmarking**: latency, throughput, and performance visualization
- ğŸ“¦ **Python Wrapper** for easy interaction:  
  ```python
  from TServe import ModelAPI
  api = ModelAPI(api_key="your_key")
  response = api.predict(tensor_input)
